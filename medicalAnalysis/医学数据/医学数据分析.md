## 第一题：生存泳道图 

 下图是发表在《肿瘤学病理》杂志中某篇文章的配图。这篇文章讨论某一肿瘤指标 PD-L1的生存分析survival analysis，做出在此类研究上常见的生存泳道图（swimmer plot）。有一些专门的软件可以画这类图，比如SAS（[https://blogs.sas.com/content/graphicallyspeaking/2014/06/22/swimmer-plot/](https://www.douban.com/link2/?url=https%3A%2F%2Fblogs.sas.com%2Fcontent%2Fgraphicallyspeaking%2F2014%2F06%2F22%2Fswimmer-plot%2F&link2key=5c3524083f)），Graphpad Prism和R语言的一些专用包。也都可以用python完成，目前很少有人弄过。这里主要是读入数据做出下图。

医学研究中常会将患者按不同的治疗组或病情进行分组，然后在同一张图中绘制多条生存曲线（类似泳道），比较不同组的生存差异。

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdA2Hs_kuYt25dzPKOENoLf_JKGNFlTcTSAUk1z7ld9JWOS2OtsAYgjm7qqITeTvTNVTPEfWVxyUQ3kab6AtfjVSc24BjSxXTW7-OXl5Ps_m5kn4Up-e8V4NO7tPMPdaIZcbDiYSPK9d9hK4x3Keg865VBg?key=74GKSa2hPIDEeb9g1q7RMg)

注意：这张图里的数据都是虚假数据。这里是对某一个肿瘤指标PD-L1，在术后对病人进行回访的数据。横坐标是以月份为单位的时间，纵坐标是病人的编号或者代号。这里总共有10个病人，按照回访月份从长到短排列。如果回访时刻已死亡，用黑圆点表示；如果还生存，用向右箭头表示。10个病人总共有三种情况：阳性转阴，阴性转阳，没有变化，这三种情况用不同颜色表示。

---

需要安装python 3.0以上，matplotlib,pandas,使用pip install或pip3 install安装
将python代码保存为medicalSurvivalBar.py

运行：`python medicalSurvivalBar.py`

或者 `python3 medicalSurvivalBar.py`

Python完整源代码如下：

```python
import matplotlib.font_manager
from matplotlib.patches import Patch
import matplotlib.patches as mpatches
import matplotlib.pyplot as plt
import pandas as pd

# import seaborn as sns
from matplotlib.lines import Line2D
from matplotlib.pyplot import figure
from PIL import Image
import io
plt.rcParams.update({'font.size': 12})

##group number:
# 1=from positive to negative，
# 2=from negative to positive，
# 3=remain unchanged

##-------------- data list ------------------
# pd-l1, os
month = [90,80,64,56,40,35,32,20,18,11]
patientID = [8,7,6,4,3,5,9,1,2,10]
group = [3,1,3,3,3,3,2,1,2,3]
death=[0,1,0,0,1,0,0,0,0,1]

# change numeric ID to string, as y axis

patientStr = [str(kk) for kk in patientID]
color = ['peru', 'teal', 'gray']
index = group
data = {'patient': patientStr, 'month': month, 'group': group, 'death': death}
df = pd.DataFrame(data,index=index)

#[color_dict = {&](https://www.douban.com/search?q=%23color_dict%20%3D%20%7B%26amp%3B%23)#x27;a':'teal', 'b': 'red', 'c':'blue', 'd': 'paleturquoise'}

## according to the group number, giving different colors to the bar
clrs = []
for x in group:
   if x==1:
       clrs.append('teal')
   elif x==2:
       clrs.append('peru')
   elif x==3:
       clrs.append('paleturquoise')

## Assign each bar with a marker indicating death (black dot, 'o'/arrow, '#$\u2192$' in unicode)

## you can use a single array, but here I used two to adjust their sizes and colors separately

mark_dot = []
mark_arrow = []
## you can select sub-set of patients by death/on-going treatment

# trunc_patient=[]

# trunc_month=[]

index0 = 0

## plot markers on the bar, indicating death (black dot, 'o') or on-going treatment (black arrow, '#$\u2192$' in unicode)

for x in death:
   if x==0:
       mark_dot.append('o')
       mark_arrow.append('')
   elif x==1:
       mark_dot.append('')
       mark_arrow.append(u'$\u2192$')
       #trunc_patient.append(patientStr[index0])
       #trunc_month.append(month[index0])
   index0 = index0+1   

# sort data by length of the month
df = df.sort_values(by=['month'])
## alternative labels
#label1 = mpatches.Patch(color='teal', label='+ to -')
#label2 = mpatches.Patch(color='peru', label='- to +')
#label3 = mpatches.Patch(color='paleturquoise', label='No difference')
##plt.legend(handles=[label1])
##plt.legend(handles=[label2])
##plt.legend(handles=[label3])
# Create the figure

fig, ax = plt.subplots(figsize=(10,8))
#ax = plt.subplots()
legend_elements = [Line2D([0], [0], color='teal', lw=6, label='from positive to negative'),

                 Line2D([0], [0], color='peru', lw=6, label='from negative to positive'),

                 Line2D([0], [0], color='paleturquoise', lw=6, label='remained unchanged'),

                 Line2D([0], [0], marker='o', color='w', label='death',markerfacecolor='black', markersize=10),

                 Line2D([0], [0], marker=u'$\u2192$', color='w', label='ongoing treatment',markerfacecolor='black', markersize=20),

                 ]

ax.legend(handles=legend_elements, loc='upper right')

df.plot.barh(y='month',x='patient', color=clrs, legend=None, ax=ax)#legend=None)#[, marker=&](https://www.douban.com/search?q=%23%2C%20marker%3D%26amp%3B%23)#x27;o')

#plt.plot(df.month,df.patient, marker=mark, linestyle="", alpha=0.8, color="r")

## plot
for xp, yp, m in zip(df.month, df.patient, mark_dot):
  plt.scatter(xp, yp, marker=m, s=80, c="black")

for xp, yp, m in zip(df.month, df.patient, mark_arrow):
  plt.scatter(xp, yp, marker=m, s=290, c="black")

## another way to plot arrows

#[arrow = u&](https://www.douban.com/search?q=%23arrow%20%3D%20u%26amp%3B%23)#x27;$\u2192$' ## arrow in unicode

#ax.plot(trunc_month, trunc_patient, linestyle='', marker=arrow, markersize=15, color='#000000')
hfont = {'fontname':'arial'}
plt.title('PD-L1, OS')

#plt.ylabel('Patients enrolled in the study')

#plt.xlabel('Time from Treatment (Months)')

plt.ylabel('Patient ID',**hfont)
plt.xlabel('Time from BM surgery (months)',**hfont)
plt.show()

# Load this image into PIL

#png1 = io.BytesIO()

#fig = plt.figure(figsize=(5,5), dpi=300)

#fig.savefig(png1, format='png')

#

## (2) load this image into PIL

#png2 = Image.open(png1)

#

## (3) save as TIFF

#png2.save('3dPlot.tiff')

#png1.close()

#png2 = Image.open(png1)
```


## 第二题：趋势分析

The Relationship of Dietary Lipid Intake and Age-Related Macular Degeneration in a Case-Control Study AREDS Report No.20
一文中，

P for trend是回归模型里线性趋势性检验的结果。


“Odds ratio”（简称OR）即**优势比**，是统计学和医学研究中用来衡量两组之间某个事件发生的相对机会的比值。它通常用于病例对照研究和队列研究，以评估某个因素与某种结局之间的关联性。

具体来说，优势比是两组中某个事件的发生几率（odds）的比值：

- 若 OR = 1，表示没有关联，两组发生事件的几率相同。
- 若 OR > 1，表示该因素与事件之间存在正相关，即该因素可能增加事件发生的机会。
- 若 OR < 1，表示该因素与事件之间存在负相关，即该因素可能减少事件发生的机会。

例如，在医学研究中，优势比可以用来评估吸烟与某种疾病之间的关系。如果 OR 为 2，这意味着吸烟者患该病的几率是非吸烟者的两倍。

具体计算方法：

Odds Ratio=$\frac{(c/d)}{(a/b)​}= \frac{a \times d}{b \times c}$

- `a` = 暴露组中事件发生的次数
- `b` = 暴露组中事件未发生的次数
- `c` = 对照组中事件发生的次数
- `d` = 对照组中事件未发生的次数
​
假设我们要计算某种治疗对疾病的影响，数据如下：

|     | 患病（是）  | 患病（否    |
| --- | ------ | ------- |
| 治疗组 | a = 50 | b = 150 |
| 对照组 | c = 30 | d = 170 |

OR=(150×30)/(50×170)​=4500/8500​≈1.89

胜算比为 1.89 意味着在治疗组中，患病的可能性是对照组的 1.89 倍。
- **OR = 1**：在两组中事件发生的可能性相同。
- **OR > 1**：治疗组中事件发生的可能性更高。
- **OR < 1**：治疗组中事件发生的可能性更低。

胜算比通常用于了解暴露与结果之间的关联强度。

`pip install pymannkendall`
https://pypi.org/project/pymannkendall/
https://www.analyticsvidhya.com/blog/2023/07/mann-kendall-trend-test-using-python/
### P for Trend

（chatGPT）

“P for trend” 通常用于衡量某种变量的趋势显著性，特别是在分组数据或者有序数据的情境下。例如，当我们研究某个连续变量（如剂量、时间、收入等）对某个结果变量（如疾病发生率、销售额等）的影响时，往往会将连续变量分组（例如按剂量或收入水平分为高、中、低组），然后计算这些组的结果变量是否呈现显著的线性趋势。

- 具体解释：P for trend 是对趋势的统计检验，检验的是多个组之间是否存在单调变化的关系，比如随着剂量增加，疾病发生率是否线性增加或减少。它回答的问题是：结果变量是否随着预测变量的增加呈现一致的升高或降低趋势。
    
- 如何计算：P for trend 通常使用的是基于回归模型的统计检验，例如线性回归或 logistic 回归，检测预测变量（如剂量）的线性效应。
    
- P 值的意义：和普通的 P 值一样，P for trend 小于 0.05 通常意味着在 95% 的置信水平下，趋势显著存在。
    
要计算趋势的 p 值，通常需要进行统计检验，例如线性回归或 Mann-Kendall 趋势检验，具体取决于数据的类型。

https://www.analyticsvidhya.com/blog/2023/07/mann-kendall-trend-test-using-python/

下表列出的是印度某地火车脱轨事故次数。当地的部门通过更多的人员培训、技术更新、设备维护后，可以看到逐年下降的趋势。

| **年份** | **出轨事故次数** |
| ------ | ---------- |
| 2001   | 350        |
| 2002   | 280        |
| 2003   | 218        |
| 2004   | 202        |
| 2005   | 138        |
| 2006   | 131        |
| 2007   | 96         |
| 2008   | 100        |
| 2009   | 85         |
| 2010   | 80         |
| 2011   | 80         |
| 2012   | 55         |
| 2013   | 49         |
| 2014   | 53         |
| 2015   | 63         |
| 2016   | 65         |
``` python
!pip install seaborn 
import seaborn as sns 
import matplotlib.pyplot as plt 
fig = plt.subplots(figsize=(20, 5)) 
sns.lineplot(x='Year', y='Derailments', data=df) 
sns.set_theme(style='white', font_scale=3)
```

![[Pasted image 20240923164821.png]]
从上图可以清楚地看到有一个下降趋势。但我们能说这个下降趋势是显著的吗？尽管从图中看，趋势很可能是显著的，让我们使用曼-肯德尔(Mann-Kendall,缩写M-K)趋势假设检验来确认这一点。

步骤：

- **原假设 ($H_0$)**：数据中没有单调趋势。
- **备择假设 ($H_1$)**：存在趋势。趋势可以是单调上升的正趋势或单调下降的负趋势。
- **检验统计量**：M检验生成一个称为“T”的统计量。T为正值表示趋势上升，而T为负值表示趋势下降。T的大小代表趋势的强度。
- **显著性水平 ($\alpha$)**：选择一个显著性水平（如0.05或0.10）来确定统计显著性的阈值。这表示当数据中实际上没有趋势时，观察到某个趋势的最大可能性。
- **P值**：M-K检验计算一个P值，量化在原假设成立的情况下，观察到的统计量与实际统计量一样极端的可能性。P值代表反对原假设的证据。
    - 如果P值小于显著性水平 (p < α)，这表明有强有力的证据可以拒绝原假设。这意味着数据中存在显著的趋势。
    - 如果P值大于或等于显著性水平 (p ≥ α)，这表明没有足够的证据拒绝原假设。这意味着数据中没有显著的趋势。
- **结论**：根据P值和显著性水平，可以得出关于数据中是否存在显著趋势的结论。
    - 如果p < α，可以得出结论，数据中存在显著的趋势。请确保根据检验统计量T的符号考虑趋势的方向。
    - 如果p ≥ α，可以得出结论，数据中没有显著的趋势。没有足够的证据表明存在趋势。
### 结论 
趋势在下降，P值非常显著。因此，我们拒绝原假设，得出结论，列车脱轨事故随时间显著减少。技术进步和基础设施的变化导致了脱轨相关事故的显著减少。

**稳健且多功能**: M-K检验对离群值具有鲁棒性，并且不假设特定的数据分布。 
**广泛适用性**：M-K检验在多个领域中有广泛应用，包括气候科学、水文学、环境监测、经济学以及其他处理时间序列数据的学科。
**简单计算**：M-K统计量的计算涉及对数据进行排序，确定成对差异的符号，并对这些符号求和。然后使用得到的统计量来评估是否存在趋势。

``` python
mk.original_test(df["Derailments"])
```


Q1. What are the assumptions of the Mann-Kendall test?

A. The Mann-Kendall test is a non-parametric or distribution-free test, meaning it does not assume any specific probability distribution for the data. It is also not affected by outliers. Though, it assumes that the observations are independent and that there are no serial correlation in the data.

Q2. How does the Mann-Kendall test work?

A. The test generates the no. of concordant and discordant pairs within the time series data. It uses these pairs to compute a test statistic that follows a normal distribution under the null hypothesis of no trend. The test statistic is then compared to critical values to determine if the trend is statistically significant.

Q3. What is the scope of Mann-Kendall?

A. Any time series related data can be tested for monotonously significant. For example the temperature across the world is increasing can be tested (Global warming Phenomenon), ice-berg is melting faster, the sea-level is monotonously increasing, islands has disappeared overtime. In the medical field- More number of patient are being diagnosed with diabetes, heart failure problem, obesity.

 Q4. Can the Mann-Kendall test determine the direction of the trend?

A. Yes, it can determine the direction of the trend. The sign of the test statistic (positive or negative) indicates the direction of the trend: positive for an increasing trend and negative for a decreasing trend. A test statistic of zero suggests no trend.

Q5. Are there any alternatives to the Mann-Kendall test?

A. Alternative trend tests, such as the Sen’s slope estimator, the Spearman’s rank correlation test, and the Theil-Sen estimator have different assumptions. Maybe more suitable depending on the specific characteristics of the data or research question.


![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeRqUZbejVtllTn-R8WW6-nJgiuYMAYfbB0n8Ft5MzwTTjqCG8iKe9n-V93XT9qmfEau_I-zsXwBjtLR-dV8u4eKB1e9TpbDBJFTNuHWsKmOkZ_uyUGW-65MLwQkT3-gbt5TsQ5jweQMsdCprMPQy6VbmnH?key=74GKSa2hPIDEeb9g1q7RMg)

![[Pasted image 20240929211236.png]]
![[Pasted image 20240929211256.png]]


Table 2
“Quintile”（五分位数）是统计学中的一个术语，用于将数据集按大小分成五个相等的部分，每部分包含数据的20%。在经济学、社会科学等领域，五分位数常用于对数据进行分组，以便分析特定变量（如收入、支出等）的分布情况。

例如，收入分布中的五分位数可以将整个收入人群分为五组，从最低收入组（第一个五分位）到最高收入组（第五个五分位），这样可以比较不同收入水平群体之间的差异。

Table 3



Table 4

![[Pasted image 20240929210710.png]]

高分层(upper strata) 第4和第5个五分位数
低分层(lower strata)  第1和第2个五分位数
Here’s a Python example of calculating the p-value for a linear trend using scipy.stats.linregress

花生四烯酸(arachidonic acid, AA)
长链多不饱和脂肪酸(long-chain polyunsaturated fatty acids, LCPUFAs)****
  
**Colinearity(共线性)** 是指在统计学和多元回归分析中，多个自变量之间存在高度线性相关的情况。换句话说，如果一个自变量可以用其他自变量的线性组合来表示，就称这些变量之间存在共线性。

在回归模型中，共线性可能会导致以下问题：

1. **回归系数不稳定**：由于自变量之间的高度相关性，回归系数的估计值可能会变得不稳定，导致模型难以解释。
2. **难以确定变量的重要性**：由于自变量之间高度相关，难以判断哪个变量对因变量有更大的影响。

共线性可以通过一些方法来检测和解决，比如计算方差膨胀因子（VIF）或者对变量进行降维处理（如主成分分析，PCA）。
## 第三题 机器学习、深度学习相关

  

[https://github.com/jeya-maria-jose/Medical-Transformer](https://github.com/jeya-maria-jose/Medical-Transformer)

https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/

https://github.com/perone/medicaltorch

  
  

如何划分训练集，测试集与验证集。

摘自：Best Use of Train/Val/Test Splits, with Tips for Medical Data

  
  

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfdQvK5JQjqrwfrVJUq--4_FAlSWU9Tm9k-TzuHB5WTSC7p4bzRyyYO-lJMgjCYNA88N9pT6Wc0zOxZSlkCqs0X-qBF7Uhn7lI4nXkydWQ4EHsswvVFw8MAlkqMXkB_QOR04FKk84-oyRis1tiaiIfm7-Sa?key=74GKSa2hPIDEeb9g1q7RMg)

  

为了训练和测试我们的模型，我们应将数据分为三个不同的数据集。

训练集  
训练集是用于训练模型并让模型学习数据中的隐藏特征/模式的一组数据。

在每个训练周期中，相同的训练数据会被重复输入到神经网络架构中，模型不断学习数据的特征。

训练集应包含多样化的输入，以便模型在各种情况下进行训练，并能预测将来可能出现的任何未见过的数据样本。

验证集  
验证集是一组独立于训练集的数据，用于在训练期间验证模型的性能。

这个验证过程提供了信息，帮助我们相应地调整模型的超参数和配置。它类似于一个批评者，告诉我们训练是否朝着正确的方向前进。

模型在训练集上进行训练，同时在每个训练周期后对验证集进行模型评估。

将数据集分成验证集的主要目的是防止模型过拟合，即模型在训练集上表现很好，但不能在未见过的数据上进行准确的分类。

测试集  
测试集是一组独立于训练集和验证集的数据，用于在训练完成后测试模型。

它提供了一个无偏见的最终模型性能评估指标，如准确率、精确率等。简单来说，它回答了“模型表现如何？”这个问题。

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdkL67A5bnKh5twbYI0zyaSeOAP5m2aQq3ievYf53CxcWhde2Ufy8hclp1C1gbPiY30FqGvFhGXn2-NGfGXy8ToVjRejmhUY8wSYuPgsI9ZicC8hSRUscVM3PhJ7kYNLDoEc5TgGCd_k613GQay5b1qGdI6?key=74GKSa2hPIDEeb9g1q7RMg)

如何划分机器学习数据？  
创建不同的数据样本和划分有助于我们判断模型的真实表现。

数据集的划分比例取决于数据集中的样本数量和模型的特点。

一些关于数据集划分的常见推论包括：

- 如果有多个超参数需要调整，机器学习模型需要更大的验证集来优化模型性能。同样地，如果模型的超参数较少或没有超参数，那么使用较小的数据集也可以轻松验证模型。
    
- 如果模型的应用场景中错误预测会严重影响性能，比如错误预测癌症，最好在每个训练周期后验证模型，以让模型学习各种情境。
    
- 随着数据维度/特征的增加，神经网络函数的超参数也会随之增加，导致模型变得更加复杂。在这种情况下，应将更多的数据划分到训练集中，同时保留一个验证集。
    

  
  
  

[https://aws.amazon.com/blogs/machine-learning/training-large-language-models-on-amazon-sagemaker-best-practices/](https://aws.amazon.com/blogs/machine-learning/training-large-language-models-on-amazon-sagemaker-best-practices/)

=============================================================
为什么要划分数据集？如何划分？

下面这篇转载文章介绍了将数据集划分为训练集、验证集和测试集的适当方法，以及如何最大限度地利用这些数据集。文章还讨论了与医疗数据相关的概念，强调医疗数据的基本单位是患者，而不是单个样本。

原链接：[https://glassboxmedicine.com/2019/09/15/best-use-of-train-val-test-splits-with-tips-for-medical-data/](https://glassboxmedicine.com/2019/09/15/best-use-of-train-val-test-splits-with-tips-for-medical-data/)

### 基础知识

如果你已经熟悉将数据集划分为训练集、验证集和测试集的基本理念，可以跳过这一部分。否则，下面将解释我们在机器学习中如何以及为什么要进行数据划分。

监督学习的数据集由样本组成。根据任务的不同，一个样本可能是一张图片、一个视频、一句话、一段文本或一段音频。每个样本都与一个标签配对，例如“猫”或“狗”这样的类别。

在项目的开始阶段，数据科学家将所有样本划分为三个子集：训练集、验证集和测试集。常用的划分比例为：

- 70% 训练集，15% 验证集，15% 测试集
    
- 80% 训练集，10% 验证集，10% 测试集
    
- 60% 训练集，20% 验证集，20% 测试集  
    （关于这些比例的更多评论见下文。）
    

接下来，这三个数据集的用途如下图。

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcUmgIW9DPzqEn74DCOylsQ2z72_lcx0FFXixh-vovoAahvG3vZRRhsuTHMpb2ivYwcGGWNZ1Fw3mAAHaN4WN5Kk3z3yDROPenK1AqeJxUxJp5DlPIcCKNrsF1vsao5TWL3F5khHtJ2IAiMgpN6ipxNqpAt?key=74GKSa2hPIDEeb9g1q7RMg)

  
假设这里我们有三个模型A,B,C。它们可以是三个不同的模型，比如不同结构的神经网络ResNet, VGG, AlexNet，它们各自有随机的预设参数；也可能是同一模型的不同变体，比如都是ResNet，但使用三种不同的学习率；或者更简单地，三个不同的带有预设的随机参数的拟合函数。从现有的数据中随机选出70%的数据作为测试集(training set)，分别输入这三个模型，各自得到训练后的模型（比如对拟合函数来说，找到了最佳的拟合参数）。然后从剩下的数据中随机选出15%的数据作为验证集(validation set), 最后各自输出表现参数或者评分(performance)。通过比较评分，选择一个最高评分的模型作为最佳模型，这里是模型B，然后将最后剩下的15%的数据作为测试集(test set)，输入到模型B里得到一个评分作为最后的结果。

步骤如下：

1. 随机初始化每个模型
    
2. 在训练集上训练每个模型
    
3. 在验证集上评估每个训练好的模型的表现
    
4. 选择验证集表现最好的模型
    
5. 在测试集上评估所选模型

### 为什么不能只用一个数据集？

假设我们将所有数据都用作训练集。当我们想评估模型性能时，只看训练集的表现。如果运气好，训练集的表现可能反映出模型在未见过的数据上的表现。但如果运气不好，模型可能只是记住了训练数据的例子，当我们给它一个从未见过的例子时，它可能完全失败（即“过拟合”）。我们无法判断自己是否运气好或不好——这就是我们需要验证集的原因。验证集由模型在训练中从未见过的样本组成，所以如果验证集表现良好，说明模型学到了有用的、可推广的原则。

### 为什么有了训练集和验证集，还需要测试集？

测试集的重要性在于“选择最佳模型”（基于验证集表现）的步骤本身可能导致另一种形式的过拟合。想象一下，如果你尝试了一千种不同的模型或模型变体，并记录了它们在验证集上的表现，选择验证集表现最好的模型意味着你无意中“调整”(tune)了模型以适应验证集。你在验证集上看到的“验证集上表现最好的模型”的性能值本质上是被夸大的。为了获得模型在未见过的数据上的准确评估，我们需要更多模型从来没有见过的数据，这就是测试集的用途。测试集的表现通常会比验证集稍差。

### 数据集的分配比例

很多人会问，训练集、验证集和测试集的“正确比例”是什么，但实际上并没有明确的规则。常见的比例包括70-15-15（文章作者常用）、80-10-10等。比例的权衡如下：

- 更多的训练数据的好处在于，模型可以看到更多的例子，从而有望找到更好的解决方案。如果你的训练数据集很小，模型将无法学习到一般的法则（principle），并且在验证集/测试集上的表现会很差（换句话说，没从数据里学到什么）。

- 更多的验证数据的好处在于，它可以帮助你更好地决定哪个模型是“最优的”。如果没有足够的验证数据，那么对哪个模型是“最优”的估计中会有很多噪声，可能会导致做出不好的选择。

- 更多的测试数据的好处在于，它可以让你更好地了解模型在未见过的数据上的泛化能力。如果没有足够的测试数据，那么对模型泛化能力的最终评估可能不准确。

然而，增加任何一个数据集的大小，就会减少其他数据集的样本数量，因此对于小型数据集，可以使用交叉验证等技术，具体见https://machinelearningmastery.com/k-fold-cross-validation/。

### 训练集/验证集/测试集的正确使用

一个重要的原则是：测试集只能使用一次。或者叫测试集一次性（YOTO）法则（英文为：YOTO，为这句话的缩写：**Y**ou **O**nly use the **T**est set **O**NCE.）。
开发模型时，所有与模型架构和超参数相关的决策都应通过验证集完成，如选择层数、神经元数量、使用何种激活函数等。测试集应仅用于评估最终确定的最佳模型的表现。

如果一名数据科学家想开发一个新的模型来解决问题，他们检查了大量不同模型在测试集上的表现，然后报告表现最好的那个模型的测试集表现，这是作弊。他们通过反复检查测试集的表现，已经对测试集过拟合了。测试集的表现指标不再是模型泛化能力的可信指标。

那么，测试集的正确使用方法是什么？在谈到这个之前，我们先讨论一下验证集的正确使用方法。

验证集应该用于所有关于模型架构和超参数的决策。如果你使用的是神经网络模型，用验证集来做以下决策是合适的：

- 选择神经网络的层数（深度）；
- 选择每层的神经元数量（宽度）；
- 选择卷积神经网络（CNN）中每层的核数量/形状; (关于CNN原理，见：https://glassboxmedicine.com/2019/05/05/how-computers-see-intro-to-convolutional-neural-networks/）
- 选择是否使用残差连接以及在哪里使用； （关于残差连接，见：https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec）
- 选择是否使用预训练的特征提取器；选择使用哪个特征提取器；选择是固定还是微调该特征提取器的权重； 
- 选择激活函数：ReLU、Leaky ReLU、ELU等（更多激活函数可以参考百科：https://en.wikipedia.org/wiki/Activation_function）； 
- 选择是否使用 dropout；（关于dropout, 见https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5）
- 选择在模型的哪些部分使用 dropout；
- 选择 dropout 的概率； 
- 选择是否使用归一化及其位置：批归一化、权重归一化、层归一化等； 
- 选择优化器：Adam、Adagrad、SGD等； （Pytorch的优化器见：https://pytorch.org/docs/stable/optim.html）
- 选择学习率； 
- 选择损失函数：交叉熵、均方误差（MSE）、自定义损失函数等； （关于损失函数的简介，见https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html）
- 选择批量大小；
- 选择是否使用正则化（regularization）；选择正则化的强度。（关于神经网络的正则化，见：https://glassboxmedicine.com/2019/06/08/regularization-for-neural-networks-with-framingham-case-study/)

换句话说，你在机器学习项目中的几乎所有工作都应该只使用训练集和验证集。你应该假装测试集不存在。

关于架构/超参数优化的旁注：假设你有足够的计算资源去优化上面列表中每个模型特征的所有可能组合是不现实的。然而，你很可能会深入探索其中的几个特征。如果你对超参数优化策略感兴趣，可以参考这篇文章(https://medium.com/@byanalytixlabs/comprehensive-guide-on-hyperparameters-optimization-examples-and-more-f2682ea0a727)。如果你拥有100个GPU，显然你可以进行更多的超参数优化，而如果你只有1个GPU，优化的空间就会小得多。

一旦你基于验证集上的大量实验决定了一个最好的模型——即“史上最棒模型”，就该使用测试集了。你应该将“史上最棒模型”运行在测试集上，查看其表现，仅此一次。这就是你应该报告的模型性能。

在许多论文中，常见的做法是将“史上最棒模型”的测试集表现与其他一些表现稍差的模型进行比较。在这种情况下，实际上你不得不获取那些“稍差模型”的测试集表现……这是当前“训练-验证-测试”数据集划分方法的一个局限性。你的论文读者在脑海中会把测试集用于模型选择（但这仍然比你用测试集开发“史上最棒模型”要好得多，因为那样是作弊）。

### 医疗数据的特殊考虑

在医疗数据集上工作时，只使用一次测试集来衡量“史上最棒模型”的性能尤为重要，因为医疗数据通常难以获取和清理。你很难轻易获得“另一个测试集”，因此希望你现有的测试集只使用一次，以提供模型泛化能力的最佳估计。如果你计划将模型部署到实际环境（real-world）中，这一点更加关键。你不想错误地声称你的“心脏病风险模型”在测试集上的AUROC为0.95(关于AUROC，可见文章https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/)，而实际上由于过拟合到测试集，真实性能可能只有0.62。这种情况下，你将会使用一个糟糕的模型，给真实患者提供误导性的心脏病风险估计。

由于测试集偶尔会被滥用，一些在医疗数据上描述机器学习模型的作者开始明确强调他们正确使用了测试集。例如，在《一种用于从小数据集中检测急性颅内出血的可解释深度学习算法》（ [“An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets](https://www.nature.com/articles/s41551-018-0324-9)）一文中，Lee等人指出：“为了评估模型的性能，在模型开发过程完成后，分别要回顾性地和前瞻性地收集两个独立的测试数据集。”

换句话说，Lee等人在使用训练集和验证集开发完模型之后，才创建了测试集。这里还有一个例子。在《使用低剂量胸部CT的三维深度学习进行端到端肺癌筛查》("End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography", https://www.nature.com/articles/s41591-019-0447-x)一文中，Ardila等人使用了多个测试集，并指出:

"两个测试集都只运行了一次，以避免对模型开发产生影响。此外，所有从事建模和图像分析的人员都对测试集中的诊断结果保持不知情(blind)。"

### 为医疗数据创建训练/验证/测试集划分

医疗数据与其他类型的数据不同，因为划分必须基于患者，而不是单个样本。这适用于医疗图像、医疗文本或医疗表格数据。举例说明：

图像任务：对胸部X光片中的疾病进行分类（具体例子见文章：https://glassboxmedicine.com/2019/05/11/automated-chest-x-ray-interpretation/）。在大多数胸部X光片数据集中，同一个患者可能贡献了多张X光片。数据必须基于患者标识符进行划分，而不是单个X光片，因为同一患者的X光片之间高度相关。

文本任务：根据描述的疾病对医疗笔记进行分类。在这里，同样需要根据患者标识符进行数据划分，因为同一患者的医疗笔记高度相关。今天患有糖尿病和囊性纤维化的患者，明天也可能仍然患有这两种疾病。

表格数据任务：根据从电子病历中收集的表格数据（包括诊断、手术、药物、人口统计和实验室值）预测住院风险（具体例子见文章https://glassboxmedicine.com/2019/06/01/everything-you-need-to-know-about-preparing-tabular-data-for-machine-learning-code-included/）。假设你考虑的是一家大型医院五年期间的数据。可以肯定的是，在此期间至少会有一位患者多次住院。如果Smith先生在医院住院了3次，那么这3次住院的样本应该被分配到同一个数据集中。

通常，患者标识符是病历号（MRN）。这是受保护的健康信息的一种形式，因此如果你使用的是去识别化的数据集，将会有一个随机生成的患者标识符来替换原始的MRN。

### 总结

- 要训练和评估机器学习模型，需要将数据划分为训练集、验证集和测试集。
- 如果你正在开发一个新的机器学习模型，应该使用验证集来最终确定模型和超参数。然后，只使用测试集一次，以评估所选模型的泛化能力。
- 如果你使用的是医疗数据集，划分应基于患者标识符，而不是单个样本。

![[Pasted image 20240923165039.png]]

另一篇文章补充
[https://www.v7labs.com/blog/train-validation-test-set](https://www.v7labs.com/blog/train-validation-test-set)

[https://platform.openai.com/docs/guides/optimizing-llm-accuracy](https://platform.openai.com/docs/guides/optimizing-llm-accuracy)

[UNeXt-pytorch](https://github.com/jeya-maria-jose/UNeXt-pytorch)

[https://raw.githubusercontent.com/mateuszbuda/brain-segmentation-pytorch/master/assets/TCGA_CS_4944.png](https://raw.githubusercontent.com/mateuszbuda/brain-segmentation-pytorch/master/assets/TCGA_CS_4944.png)


![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcfG6S0yqmBzAFfn84fo4okrrdKvh6i2-BUdevQzyVoYFKs82pB2lYBodGk6gs3cIh9X_UdU7aoqYr2xR9ehw5GSPIOMaXasl3BaZpNlV6SbxFWZMM7w8ztmTypnUevQlO0I4rGL0zr7jAoFVXR5hHtdpf5?key=74GKSa2hPIDEeb9g1q7RMg)


"Acute ICH" 是指急性颅内出血（acute intracerebral hemorrhage）这是指大脑内部的血管突然破裂，导致血液积聚在脑组织内，可能压迫周围的脑组织并导致功能障碍。急性颅内出血是一种严重的脑血管疾病，常见的原因包括高血压、头部创伤、脑动脉瘤、脑血管畸形等。

急性颅内出血需要紧急处理，因为如果不及时治疗，可能会引发严重的并发症，甚至危及生命。治疗通常包括药物治疗、外科手术和病因管理。

==========================================

Ischaemic stroke（缺血性卒中）是指由于大脑的某一部分血流受阻或减少，导致脑组织缺氧，无法获得足够的营养和氧气，从而引发脑细胞损伤或死亡的状况。它是中风的最常见类型，约占所有中风病例的80%以上。

缺血性卒中的常见原因包括动脉粥样硬化（血管内壁堆积脂肪物质，形成斑块），血栓形成（血液凝块阻塞血管），以及心源性栓塞（心脏内的血凝块通过血流进入大脑，阻塞脑血管）。

  
  
  
  
  

[https://www.biowolf.cn/biodata/metabric_data.html](https://www.biowolf.cn/biodata/metabric_data.html)

[http://www.cbioportal.org/](http://www.cbioportal.org/)

  
  
  

这里面是569个病人(随意标号1到569，python数组是从0到568)，总共有30个乳腺癌指标，标记是良性还是恶性，然后 训练数据，给新的指标看能不能诊断良性恶性

  

https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html

威斯康星州乳腺癌数据集，共569个样本或569个病人的数据。这些样本一般是切片在显微镜下的图片，我们可以通过ImagJ等图像分析软件测量肿瘤细胞的直径、周长、纹理等等指标。在这里对每个病人的切片，记录30个指标/特征，其中10个指标是均值（mean)，10个是方差(standard erro)r，10个是最差值(worst)。

  

两分类标签：良性benign或恶性malignant。良性病人357个，恶性212个。

[https://github.com/cystanford/breast_cancer_data/](https://github.com/cystanford/breast_cancer_data/)

  
  

https://blog.csdn.net/Zesheng_Wang/article/details/124623202

[https://github.com/zesheng-wang/machine-learning](https://github.com/zesheng-wang/machine-learning)

  
  
  


  

``` python
import torch
import pandas as pd
import sklearn
from sklearn.datasets import load_breast_cancer
cancer_data = load_breast_cancer()
print(cancer_data.keys())
print(cancer_data[‘DESCR’])
```
  
  

**Data Set Characteristics:**
``` python
:Number of Instances: 569
:Number of Attributes: 30 numeric, predictive attributes and the class
:Attribute Information:

        - radius (mean of distances from center to points on the perimeter)

        - texture (standard deviation of gray-scale values)

        - perimeter

        - area

        - smoothness (local variation in radius lengths)

        - compactness (perimeter^2 / area - 1.0)

        - concavity (severity of concave portions of the contour)

        - concave points (number of concave portions of the contour)

        - symmetry

        - fractal dimension ("coastline approximation" - 1)

        The mean, standard error, and "worst" or largest (mean of the three

        worst/largest values) of these features were computed for each image,

        resulting in 30 features.  For instance, field 0 is Mean Radius, field

        10 is Radius SE, field 20 is Worst Radius.
        - class:

                - WDBC-Malignant

                - WDBC-Benign
    :Summary Statistics:

    ===================================== ====== ======

                                           Min    Max

    ===================================== ====== ======

    radius (mean):                        6.981  28.11

    texture (mean):                       9.71   39.28

    perimeter (mean):                     43.79  188.5

    area (mean):                          143.5  2501.0

    smoothness (mean):                    0.053  0.163

    compactness (mean):                   0.019  0.345

    concavity (mean):                     0.0    0.427

    concave points (mean):                0.0    0.201

    symmetry (mean):                      0.106  0.304

    fractal dimension (mean):             0.05   0.097

    radius (standard error):              0.112  2.873

    texture (standard error):             0.36   4.885

    perimeter (standard error):           0.757  21.98

    area (standard error):                6.802  542.2

    smoothness (standard error):          0.002  0.031

    compactness (standard error):         0.002  0.135

    concavity (standard error):           0.0    0.396

    concave points (standard error):      0.0    0.053

    symmetry (standard error):            0.008  0.079

    fractal dimension (standard error):   0.001  0.03

    radius (worst):                       7.93   36.04

    texture (worst):                      12.02  49.54

    perimeter (worst):                    50.41  251.2

    area (worst):                         185.2  4254.0

    smoothness (worst):                   0.071  0.223

    compactness (worst):                  0.027  1.058

    concavity (worst):                    0.0    1.252

    concave points (worst):               0.0    0.291

   symmetry (worst):                     0.156  0.664

   fractal dimension (worst):            0.055  0.208

   ===================================== ====== ======
   :Missing Attribute Values: None
   :Class Distribution: 212 - Malignant, 357 - Benign
   :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian
   :Donor: Nick Street
   :Date: November, 1995
This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.
```
  
``


https://goo.gl/U2Uwz2

  

Features are computed from a digitized image of a fine needle

aspirate (FNA) of a breast mass.  They describe

characteristics of the cell nuclei present in the image.

  

Separating plane described above was obtained using

Multisurface Method-Tree (MSM-T) [K. P. Bennett, "Decision Tree

Construction Via Linear Programming." Proceedings of the 4th

Midwest Artificial Intelligence and Cognitive Science Society,

pp. 97-101, 1992], a classification method which uses linear

programming to construct a decision tree.  Relevant features

were selected using an exhaustive search in the space of 1-4

features and 1-3 separating planes.

  

The actual linear program used to obtain the separating plane

in the 3-dimensional space is that described in:

[K. P. Bennett and O. L. Mangasarian: "Robust Linear

Programming Discrimination of Two Linearly Inseparable Sets",

Optimization Methods and Software 1, 1992, 23-34].

  

This database is also available through the UW CS ftp server:

  

ftp ftp.cs.wisc.edu

cd math-prog/cpo-dataset/machine-learn/WDBC/

  

.. topic:: References

  

   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction

     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on

     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,

     San Jose, CA, 1993.

   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and

     prognosis via linear programming. Operations Research, 43(4), pages 570-577,

     July-August 1995.

   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques

     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)

     163-171.

  
```python
>>> df = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])
>>> df['target'] = cancer_data['target']
>>> print(df.head())
```

调出表格，打印数据
 
   mean radius  mean texture  mean perimeter  ...  worst symmetry  worst fractal dimension  target

0        17.99         10.38          122.80  ...          0.4601                  0.11890       0

1        20.57         17.77          132.90  ...          0.2750                  0.08902       0

2        19.69         21.25          130.00  ...          0.3613                  0.08758       0

3        11.42         20.38           77.58  ...          0.6638                  0.17300       0

4        20.29         14.34          135.10  ...          0.2364                  0.07678       0

  
  

在上面这个例子中，我们把所有数据，即所有的病人和他们所有的指标作为输入数据，来和

做线性回归，得到一个拟合模型。



```python
import torch

import torch.nn as nn

import torch.optim as optim

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler

from sklearn.metrics import accuracy_score

from sklearn.datasets import load_breast_cancer

from transformers import BertModel, BertTokenizer

import numpy as np

# 1. 加载数据集

data = load_breast_cancer()

X = data['data']

y = data['target']

# 2. 数据预处理

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)

X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)

X_val = scaler.transform(X_val)

X_test = scaler.transform(X_test)

# 3. 自定义 Transformer 模型

class TransformerClassifier(nn.Module):
    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=2, num_classes=2):
        super(TransformerClassifier, self).__init__()
        self.fc_in = nn.Linear(input_dim, d_model)
        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers)
        self.fc_out = nn.Linear(d_model, num_classes)
    def forward(self, x):
        # 将输入reshape成 transformer 所需要的序列形状 (seq_len, batch_size, d_model)
        x = self.fc_in(x).unsqueeze(1)
        x = self.transformer(x, x)
        x = self.fc_out(x.squeeze(1))
        return x

# 4. 初始化模型、损失函数和优化器

model = TransformerClassifier(input_dim=X_train.shape[1])
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 5. 定义训练和评估函数

def train(model, X_train, y_train, X_val, y_val, epochs=10):
    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()
        output = model(torch.FloatTensor(X_train))
        loss = criterion(output, torch.LongTensor(y_train))
        loss.backward()
        optimizer.step()

        # 验证集准确率

        model.eval()
        with torch.no_grad():
            val_output = model(torch.FloatTensor(X_val))
            val_pred = torch.argmax(val_output, dim=1).numpy()
            val_acc = accuracy_score(y_val, val_pred)
        print(f"Epoch {epoch+1}, Loss: {loss.item()}, Validation Accuracy: {val_acc:.4f}")

def test(model, X_test, y_test):
    model.eval()
    with torch.no_grad():
        test_output = model(torch.FloatTensor(X_test))
        test_pred = torch.argmax(test_output, dim=1).numpy()
        test_acc = accuracy_score(y_test, test_pred)
    print(f"Test Accuracy: {test_acc:.4f}")

# 6. 训练模型

train(model, X_train, y_train, X_val, y_val, epochs=20)
# 7. 测试模型

test(model, X_test, y_test)
```
- 我们使用 PyTorch 实现了一个简化的 Transformer 模型，适应于特征数小的任务（如乳腺癌数据集的特征分类任务）。
    
- 该模型包含了一个线性层作为输入映射到 Transformer 模型所需要的维度，经过 Transformer 编码器后再通过一个线性层进行二分类。
    
- 数据集分为训练集、验证集和测试集，训练过程中每个 epoch 后会输出验证集的准确率，并在训练结束后进行测试集上的准确率评估。
    

你可以运行这段代码来评估乳腺癌数据集上的分类效果。如果需要进一步优化模型，可以调整 Transformer 模型的结构、超参数，或使用更复杂的数据增强和正则化技巧。

  https://www.kaggle.com/datasets/sani84/glasmiccai2015-gland-segmentation


## 医学统计论文中常见的错误

  
Peter Flom et al., Common errors in statistics and methods
文章来源：https://bmjpaedsopen.bmj.com/content/8/1/e002755

摘要

作为《BMJ Paediatrics Open》（BMJPO）的统计审稿人和编辑，我们在审阅提交到我们期刊的文章时，经常发现方法学和统计方面的错误。为了列出这些常见错误并提出适当的修正建议，并受到其他领先期刊类似努力的启发，我们对 BMJPO 的统计审稿人和编辑进行了调查，收集他们的不满之处和推荐的最佳实践示例。我们将这些错误分为七个部分：图形；统计显著性及相关问题；呈现、词汇、文本和表格呈现；因果关系；模型构建、回归和方法选择；元分析；以及其他杂项。本文将介绍这些常见错误，并附上简要说明。我们希望这里提供的指导能够帮助作者在准备提交给期刊的稿件时，提高研究报告的质量和稳健性。
- 图形  
1. 饼图  
饼图通常不是数据可视化的最佳方式。对于类别非常少的情况，使用表格或仅用文字描述会更好；而对于类别较多的情况，点图（dot plot）则更加有效。详见博客文章[Graphics for Univariate Data: Pie is Delicious but Not Nutritious | by Peter Flom | Peter Flom — The Blog | Medium](https://medium.com/peter-flom-the-blog/graphics-for-univariate-data-pie-is-delicious-but-not-nutritious-4e9f59e00085)

2.炸药图

炸药图（Dynamite plots）是数值数据的柱状图，带有显示平均值和某种不确定性度量（通常是标准误差，SE）的须和线条。它们之所以被称为“炸药图”，是因为它们看起来像带有起爆器的炸药装置，但正如炸药一样，它们经常会“引爆”误导。Koyama 列出了四个主要问题，使得从炸药图中得出结论变得困难：（1）这些图表非常低效，展示的信息太少；（2）仅显示均值往往没有太大信息量；（3）须线会妨碍视线，可能会扭曲对图表的整体解释；（4）实际数据未显示。更好的替代方案，包括显示更多数据及其分布的图表，有条形图（即当样本量较小时，显示每个数据点的图），箱线图（适用于比较多个大样本组），小提琴图或豆荚图。

- 缺乏公开访问的协议以检查报告偏倚  
大多数大型临床研究，尤其是所有随机临床试验，应该有一个事先发布的研究协议，发布在同行评审的期刊、资料库或其他稳定的在线位置。系统评价和元分析应在诸如 PROSPERO（https://www.crd.york.ac.uk/prospero/）或开放科学框架（https://osf.io/）等注册机构中注册，对于较大的项目，发布协议也可能是合适的。所有后续报告都应提供如何访问研究注册和/或协议的信息。

译者注1："Meta-analysis"（元分析/荟萃分析）是指一种统计方法，通过综合多项独立研究的结果，以评估某一特定研究问题或假设的总体效果。荟萃分析通常用于：

1. **合并数据**：将多个研究中的数据进行汇总，以提高统计效能。
2. **评估一致性**：检查不同研究结果之间的一致性，了解是否存在变异或异质性。
3. **提供更强的证据**：通过综合多个研究的结果，得出更为可靠和全面的结论。

荟萃分析在医学、心理学和社会科学等多个领域广泛应用，能够帮助研究者从整体上评估某一干预措施或变量的影响。


- 在一个组中显著，但在另一个组中不显著：交互作用？

研究者常常对变量之间的关系是否在不同数据子集中的表现相同感兴趣。一个常见的方法是分别分析每个子集，然后比较p值，通常根据在一个子集中显著、两个子集中显著，或两个子集中均不显著来得出结论。Andrew Gelman 撰写了一篇重要文章《显著’与‘不显著’之间的差异本身并没有统计学显著性》，指出即使实际差异很小，你也可能得到“显著”和“不显著”的结果；反之，即使差异很大，也可能两个结果均为显著或均不显著。这个问题更适合通过交互作用来分析。要测试交互作用，可在模型中加入交互项。为了展示交互作用，使用图形化呈现。

- Cronbach's α 系数 > 0.7 = “可靠”  
通常引用 0.7 这一标准的来源是 Nunnally（1972）或同一本书的第二版（Nunnally 和 Bernstein，1994）。我们怀疑，大多数引用这一标准的作者并没有阅读原始文本，因为原文的说法更加微妙，并没有直接指出“> 0.7 = 好”。此外，α 系数也被描述为“充满了源于不切实际假设的问题”。


- 不检查模型假设，或至少不报告这些假设

这种错误非常常见。大多数（也许所有）统计方法都基于某些假设。研究者需要意识到这些假设，检查它们并报告结果。例如，使用普通最小二乘法的多元回归有几个假设，包括：（1）参数是线性的，（2）模型设定正确，（3）误差是独立同分布(i.d.d)的，（4）误差呈正态分布。

- 不恰当地使用小数位
如果你的样本总数是105人，就不需要说你的样本中55.238%是女性——你在提供精确到每10万人中的1人的数据。同样地，如果你以年为单位测量年龄，并说平均年龄是34.561岁，那你实际上是在告诉读者一个精确到约8小时的平均年龄。我们喜欢的经验法则是，考虑任何理性的人认为足够的精确度，然后再加一位数。例如，对于以年为单位的平均年龄，精确到1年几乎肯定已经足够，因此可以报告到小数点后一位：34.6岁。对于女性百分比，报告为55.2%。

- 数值应以文字或数字形式书写  
小数值（小于10或10的倍数）应以文字形式书写。例如，不应写“我们观察到7（xx%）名儿童营养不良”，而应写“我们观察到七名儿童营养不良。我们观察到50名儿童营养不良”。对于不是10的倍数的大数值，可以这样写：“我们观察到36（xx%）名儿童营养不良”。此外，句首的数值应以文字形式书写。例如，“三十六名营养不良的儿童在我们的研究中被观察到。”或者可以这样写：“在我们的研究中观察到36（xx%）名儿童营养不良”。






- 总结  
遵循一些统计实践和呈现的基本原则将会带来更为可靠的研究结果和更清晰的文章。